---
title: "Exploring Air Quality"
author: "Daniela"
date: "5/26/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Import Data

The data came from the Air Quality Historical Data Platform, an open data framework which gathers data from worldwide EPA monitering programs.

```{r cars}
#airqualitybeijing.csv <- #"/home/CAMPUS/mwl04747/github/China_air_pollution_COVID/beijing-air-quality.csv"
airqualitybeijing.csv = "/home/CAMPUS/dapa2019/R/China_air_pollution_COVID/beijing-air-quality.csv"

AQbeijing <- read.csv(airqualitybeijing.csv)

str(AQbeijing)

```

## Scatter Plot

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(AQbeijing$pm10)
```

Dates aren't correct -- Index...

## Next Steps

- Fix Dates

 - as.Date()
 
```{r fixdates}
# Fix the dates!
AQbeijing$NewDate = as.Date(AQbeijing$date)
str(AQbeijing)
head(AQbeijing)
```


```{r}
plot(pm25 ~ NewDate, data=AQbeijing)

```


 
- Select Data Before and After Lockdown. file is city_size_lockdowndate.csv
- Different for each city? Yes 
- 80 days

#merge files, or extract by city, date. before/after by date. subset(). how can I extract a window of dates by factor. create different data frames by each window. new column where: if date before lockdown, -1, if date after lockdown +1, get rid of zeros. create binary columns.

  - subset()
  
  
```{r subset}
# Dates for Beijing: "2020-02-10" Start

AQbeijingLockDown = as.Date("2020-02-10"); str(AQbeijingLockDown)

AQbeijingBefore = subset(AQbeijing, 
        subset=(NewDate > AQbeijingLockDown-80 &
                NewDate < AQbeijingLockDown))
AQbeijingAfter = subset(AQbeijing, 
        subset=(NewDate >= AQbeijingLockDown &
                NewDate < AQbeijingLockDown + 80))

plot(pm25~NewDate, AQbeijingBefore)
plot(pm25~NewDate, AQbeijingAfter)

```


- t-test Before and After
  - t.test()
  
  
```{r ttest}
#run ttest
t.test(AQbeijingBefore$pm25, AQbeijingAfter$pm25)


```

```{r ttest}
#extract mean_before, mean_after, p-value
ttest = t.test(AQbeijingBefore$pm25, AQbeijingAfter$pm25)
ttest$estimate
ttest$p.value


#export whole ttest
capture.output(ttest, file = "Welch_output.csv", append = TRUE)

#export just city, estimate, pvalue
estimate = ttest$estimate
pvalue = ttest$p.value
city = "Beijing"
capture.output(city, estimate, pvalue, file = "output.csv", append = TRUE)


```

#repeating import data, scatterplot, fix dates, welch 2-sample t test, output for the other cities.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Import Data

The data came from the Air Quality Historical Data Platform, an open data framework which gathers data from worldwide EPA monitering programs.

```{r cars}
#airqualitybeijing.csv <- #"/home/CAMPUS/mwl04747/github/China_air_pollution_COVID/beijing-air-quality.csv"


xianning.csv = "/home/CAMPUS/dapa2019/R/China_air_pollution_COVID/data/e/xianning-air-quality.csv"

AQ <- read.csv(xianning.csv)

str(AQ)

```

## Scatter Plot

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(AQ$pm25)
```

Dates aren't correct -- Index...

## Next Steps

- Fix Dates

 - as.Date()
 
```{r fixdates}
# Fix the dates
AQ$NewDate = as.Date(AQ$date)
str(AQ)
head(AQ)
```


```{r}
plot(pm25 ~ NewDate, data=AQ)

```


 
- Select Data Before and After Lockdown
- Different for each city? Yes 
- 80 days

  - subset()
  
  
```{r subset}
# Dates for city: "yyyy-mm-dd" Start Lockdown

AQLockDown = as.Date("2020-01-24"); str(AQLockDown)

AQxianningBefore = subset(AQ, 
        subset=(NewDate > AQLockDown-80 &
                NewDate < AQLockDown))
AQxianningAfter = subset(AQ, 
        subset=(NewDate >= AQLockDown &
                NewDate < AQLockDown + 80))

plot(pm25~NewDate, AQxianningBefore) 
plot(pm25~NewDate, AQxianningAfter)

```

- t-test Before and After
  - t.test()
  
  
```{r ttest}
#run ttest
t.test(AQxianningBefore$pm25, AQxianningAfter$pm25)


```

```{r ttest}
#extract mean_before, mean_after, p-value
ttest = t.test(AQxianningBefore$pm25, AQxianningAfter$pm25)
ttest$estimate
ttest$p.value


#export whole ttest
capture.output(ttest, file = "Welch_output.csv", append = TRUE)

#export just city, estimate, pvalue
estimate = ttest$estimate
pvalue = ttest$p.value
city = "Xianning"
capture.output(city, estimate, pvalue, file = "output.csv", append = TRUE)

```


- BACI "Before and Ater Control-Impact"
  - aov() 
  
  
visualization:

- time series -- with abreak B/A
- box plot B/A



```{r}
# cityname, date, pm25: two files: one before, one after lockdown starts

#renamed cities in the file tbl from id, using sed at the command line 
#sed 's/"\/home\/CAMPUS\/dapa2019\/R\/China_air_pollution_COVID\/data\/baotou-air-quality\.csv"/baotou/g' tbl.csv>tbl2.csv
#renamed cities are in tbl_28cities.csv and tbl_2cities.csv. 
#tbl_28cities.csv includes 28 cities, excludes two problematic files (tianjin and xianning) which are in tbl_2cities.csv

library(dplyr)
library(readr)
files <- list.files(path = "/home/CAMPUS/dapa2019/R/China_air_pollution_COVID/data", pattern = "*.csv", full.names = T)

tbl.csv <- sapply(files, read_csv, simplify=FALSE) %>% 
bind_rows(.id = "id")

#write tbl as csv
write.csv(tbl, "tbl.csv")
head(tbl.csv)

#trying to include xianning and tianjin, which have no O3 values.
#opened tbl_2cities in BBEdit, found that o3 included TRUE (likely an unspecified trace amount) and NA, changed TRUE to NA and renamed to tbl_2cities_editedbetter.csv
#merge 28 and 2:
cities2 <- read.csv("/home/CAMPUS/dapa2019/R/China_air_pollution_COVID/tbl/tbl_2cities_editedbetter.csv")
cities28  <- read.csv("/home/CAMPUS/dapa2019/R/China_air_pollution_COVID/tbl/tbl_28cities.csv")

str(cities2)

cities30 <- rbind(cities2, cities28)
write.csv(cities30, "/home/CAMPUS/dapa2019/R/China_air_pollution_COVID/tbl/cities30.csv")
head(cities30)

str(cities30) #date column is formatted as yyyy/mm/dd

```

## Next Steps

 
```{r fixdates}
# Fix the dates! Change from <factor> (date column) to <date> (newdate column).
cities30$newdate = as.Date(cities30$date) #newdate format is yyyy-mm-dd
str(cities30)
head(cities30)


```{r}
plot(pm25 ~ newdate, data=cities30) #points instead of circles, rotate y-axis, change labels from newdate etc. to be more readable, points--> grey. instert a moving average regression line. 
#look into AIC
str(cities30)
```




The goal of the next section is to split the cities30.csv into four new csv files:
the 80 days leading up to the date of lockdown in 2020
the 80 days after and including the date of lockdown in 2020
the same two ranges of dates but for 2019



```{r}
#this file includes city name and the date of lockdown formatted yyyy-mm-dd
city_size_lockdowndate.csv = "/home/CAMPUS/dapa2019/R/China_air_pollution_COVID/city_size_lockdowndate.csv"
lockdowndate <- read.csv(city_size_lockdowndate.csv)

str(lockdowndate)


#before newdate > "2020-02-10"-80 & newdate < "2020-02-10")}

#after newdate >= "2020-02-10" & newdate < "2020-02-10"+80)}

#worked with a duplicate file (same as cities30) for experimenting
cities30_duplicate = "/home/CAMPUS/dapa2019/R/China_air_pollution_COVID/tbl/cities30_duplicate.csv"
duplicate <- read.csv(cities30_duplicate)
newdate <- cities30$newdate

#CITY2020BEFORE GUIDELINE

beijing_beforelockdown2020 <- subset(cities30, subset=c(id=="beijing" & newdate > as.Date("2020-02-10")-80 & newdate < "2020-02-10"))
str(beijing_beforelockdown2020)
#write.csv(beijing_beforelockdown2020, "/home/CAMPUS/dapa2019/R/China_air_pollution_COVID/data/beforelockdown2020/beijing_beforelockdown2020.csv")

#results can be accessed as .csv files or as data frames.

all_beforelockdown2020 <- do.call("rbind", list(beijing_beforelockdown2020, wuhan_beforelockdown2020, xianning_beforelockdown2020, tangshan_beforelockdown2020, wuxi_beforelockdown2020, nanjing_beforelockdown2020, hangzhou_beforelockdown2020, xuzhou_beforelockdown2020, changzhou_beforelockdown2020, dalian_beforelockdown2020, nanchang_beforelockdown2020, benxi_beforelockdown2020, dandong_beforelockdown2020, fuxin_beforelockdown2020, hefei_beforelockdown2020, huludao_beforelockdown2020, panjin_beforelockdown2020, yangzhou_beforelockdown2020, jinzhou_beforelockdown2020, tianjin_beforelockdown2020, yibin_beforelockdown2020, ganzhou_beforelockdown2020, guangzhou_beforelockdown2020, chuzhou_beforelockdown2020, suzhou_beforelockdown2020, fangchenggang_beforelockdown2020, cangzhou_beforelockdown2020, shanghai_beforelockdown2020, baotou_beforelockdown2020, chifeng_beforelockdown2020))

write.csv(all_beforelockdown2020, "/home/CAMPUS/dapa2019/R/China_air_pollution_COVID/data/all_beforelockdown2020.csv")

#CITY2020AFTER GUIDELINE
beijing_afterlockdown2020 <- subset(cities30, subset=c(id=="beijing" & newdate >= "2020-02-10" & newdate < as.Date("2020-02-10")+80))
head(beijing_afterlockdown2020)
write.csv(beijing_afterlockdown2020, "/home/CAMPUS/dapa2019/R/China_air_pollution_COVID/data/afterlockdown2020/beijing_afterlockdown2020.csv")

all_afterlockdown2020 <- do.call("rbind", list(beijing_afterlockdown2020, wuhan_afterlockdown2020, xianning_afterlockdown2020, tangshan_afterlockdown2020, wuxi_afterlockdown2020, nanjing_afterlockdown2020, hangzhou_afterlockdown2020, xuzhou_afterlockdown2020, changzhou_afterlockdown2020, dalian_afterlockdown2020, nanchang_afterlockdown2020, benxi_afterlockdown2020, dandong_afterlockdown2020, fuxin_afterlockdown2020, hefei_afterlockdown2020, huludao_afterlockdown2020, panjin_afterlockdown2020, yangzhou_afterlockdown2020, jinzhou_afterlockdown2020, tianjin_afterlockdown2020, yibin_afterlockdown2020, ganzhou_afterlockdown2020, guangzhou_afterlockdown2020, chuzhou_afterlockdown2020, suzhou_afterlockdown2020, fangchenggang_afterlockdown2020, cangzhou_afterlockdown2020, shanghai_afterlockdown2020, baotou_afterlockdown2020, chifeng_afterlockdown2020))

write.csv(all_afterlockdown2020, "/home/CAMPUS/dapa2019/R/China_air_pollution_COVID/data/all_afterlockdown2020.csv")

head(all_afterlockdown2020)

```
repeating the above for 2019
```{r}

#CITY2019BEFORE GUIDELINE

chifeng_beforelockdown2019 <- subset(cities30, subset=c(id=="chifeng" & newdate > as.Date("2019-02-13")-80 & newdate < "2019-02-13"))
head(chifeng_beforelockdown2019)
write.csv(chifeng_beforelockdown2019, "/home/CAMPUS/dapa2019/R/China_air_pollution_COVID/data/beforelockdown2019/chifeng_beforelockdown2019.csv")

all_beforelockdown2019 <- do.call("rbind", list(beijing_beforelockdown2019, wuhan_beforelockdown2019, xianning_beforelockdown2019, tangshan_beforelockdown2019, wuxi_beforelockdown2019, nanjing_beforelockdown2019, hangzhou_beforelockdown2019, xuzhou_beforelockdown2019, changzhou_beforelockdown2019, dalian_beforelockdown2019, nanchang_beforelockdown2019, benxi_beforelockdown2019, dandong_beforelockdown2019, fuxin_beforelockdown2019, hefei_beforelockdown2019, huludao_beforelockdown2019, panjin_beforelockdown2019, yangzhou_beforelockdown2019, jinzhou_beforelockdown2019, tianjin_beforelockdown2019, yibin_beforelockdown2019, ganzhou_beforelockdown2019, guangzhou_beforelockdown2019, chuzhou_beforelockdown2019, suzhou_beforelockdown2019, fangchenggang_beforelockdown2019, cangzhou_beforelockdown2019, shanghai_beforelockdown2019, baotou_beforelockdown2019, chifeng_beforelockdown2019))

write.csv(all_beforelockdown2019, "/home/CAMPUS/dapa2019/R/China_air_pollution_COVID/data/all_beforelockdown2019.csv")


#CITY2019AFTER GUIDELINE
chifeng_afterlockdown2019 <- subset(cities30, subset=c(id=="chifeng" & newdate >= "2019-02-13" & newdate < as.Date("2019-02-13")+80))
head(chifeng_afterlockdown2019)
write.csv(chifeng_afterlockdown2019, "/home/CAMPUS/dapa2019/R/China_air_pollution_COVID/data/afterlockdown2019/chifeng_afterlockdown2019.csv")

all_afterlockdown2019 <- do.call("rbind", list(beijing_afterlockdown2019, wuhan_afterlockdown2019, xianning_afterlockdown2019, tangshan_afterlockdown2019, wuxi_afterlockdown2019, nanjing_afterlockdown2019, hangzhou_afterlockdown2019, xuzhou_afterlockdown2019, changzhou_afterlockdown2019, dalian_afterlockdown2019, nanchang_afterlockdown2019, benxi_afterlockdown2019, dandong_afterlockdown2019, fuxin_afterlockdown2019, hefei_afterlockdown2019, huludao_afterlockdown2019, panjin_afterlockdown2019, yangzhou_afterlockdown2019, jinzhou_afterlockdown2019, tianjin_afterlockdown2019, yibin_afterlockdown2019, ganzhou_afterlockdown2019, guangzhou_afterlockdown2019, chuzhou_afterlockdown2019, suzhou_afterlockdown2019, fangchenggang_afterlockdown2019, cangzhou_afterlockdown2019, shanghai_afterlockdown2019, baotou_afterlockdown2019, chifeng_afterlockdown2019))

write.csv(all_afterlockdown2019, "/home/CAMPUS/dapa2019/R/China_air_pollution_COVID/data/all_afterlockdown2019.csv")


all_2019 <- rbind(all_beforelockdown2019, all_afterlockdown2019)
all_2020 <- rbind(all_beforelockdown2020, all_afterlockdown2020)

```
 
#plotting all cities data
#scatterplots
#boxplots

```{r}


library(RColorBrewer)
display.brewer.all()

#points instead of circles, rotate y-axis, change labels from newdate etc. to be more readable, points--> grey. instert a moving average regression line. 

ggplot(all_afterlockdown2020, aes(newdate, pm25), color="firebrick")

#type-c
library(lattice)
xyplot(pm25 ~ newdate, data=all_afterlockdown2020, 
       auto.key=list(space="right"), main="Pollution After Lockdown", xlab="Date", ylab="PM 2.5", 
       jitter.x=TRUE, jitter.y=TRUE, type=c("p","smooth"), col=brewer.pal(3, "YlOrRd"), pch = 16, cex=.4)  
#cannot add groups=pm25. how to impose gradient?

install.packages("tidyverse")

g <- ggplot(all_afterlockdown2020, aes(newdate, pm25)) 
g + scale_colour_gradient(low = "yellow", high = "red", space = "Lab", na.value = "grey50", guide = "colourbar", aesthetics = "colour") #no result
g + scale_colour_brewer(type = "seq", palette = "YlOrRd", direction = 1, aesthetics = "colour")  #no result

#for LOESS
library(dplyr)
  all_afterlockdown2020 %>%
  mutate(loess = predict(loess(pm25 ~ newdate, data = all_afterlockdown2020))) %>%
  ggplot(aes(newdate, pm25)) +
  geom_point(color = "grey50") +
  geom_smooth(aes(pm25 = loess)) #not working
  


#ggplot(all_afterlockdown2020, aes(newdate, pm25)) + 
#geom_point(alpha=.4, size=.8, aes(colour=factor(pm25))) +
#geom_smooth(method = "loess", se = FALSE, colour="black") + theme(legend.position='none', panel.background = element_blank()) + scale_colour_brewer(type = "seq", palette = "YlOrRd", direction = 1, aesthetics = "colour") #n too large, allowed maximum for palette YlOrRd is 9 Returning the palette you asked for with that many colors

#ggplot(all_afterlockdown2020, aes(newdate, pm25)) + 
#geom_point(alpha=.4, size=.8, aes(colour=factor(pm25))) +
#geom_smooth(method = "loess", se = FALSE, colour="black") + theme(legend.position='none', panel.background = element_blank()) + scale_color_gradient2(low = "yellow", mid = "orange", high = "red", midpoint = mean(pm25)) #error discrete values applied to a continuous scale


ggplot(all_afterlockdown2020, aes(newdate, pm25), jitter.x=TRUE, jitter.y=TRUE, auto.key=list(space="right")) + labs(x="Date", y="PM 2.5", title="PM 2.5 Pollution Levels After 2020 Lockdowns") +
geom_point(alpha=.4, size=.8, aes(colour=factor(pm25))) +
geom_smooth(method = "loess", se = FALSE, colour="black") + theme(legend.position='none', panel.background = element_blank()) #WORKS but how to change the gradient color? I'm hoping to use the brewer color palatte YlOrRd


#overall patterns are more obvious here:
ggplot(all_2020, aes(newdate, pm25), jitter.x=TRUE, jitter.y=TRUE, auto.key=list(space="right")) + labs(x="Date", y="PM 2.5", title="PM 2.5 levels during 80 days before and after lockdown") +
geom_point(alpha=.4, size=.8, aes(colour=factor(pm25))) + 
geom_smooth(method = "loess", se = FALSE, colour="black") + theme(legend.position='none', panel.background = element_blank()) #hope to graph all2019 and all2020 with a "divider" marking lockdowndate.


plot(y=all_2020$pm25, x=all_2020$newdate)

plot(all_beforelockdown2020$newdate, all_beforelockdown2020$pm25, type="l",col="red", xlim=as.Date(c("2019-10-05","2020-06-01")))
lines(all_afterlockdown2020$newdate, all_afterlockdown2020$pm25,col="green") #fix date range.



#make grpah for each pollutatnt type
#fix boxplots to work with means
#find real population sizes (even if old) preferably from same source.
#ask email questions!


#learn overall format for a mult. regression
#proximity to factories
#coastal vs inland
#general geography (eg. elevation)
#duplicate_sorting = subset(duplicate, subset=c(id == "beijing"))
#duplicate_sorting2 = subset(duplicate_sorting, subset=c(newdate < "2020-02-10"))
#duplicate_sorting3 = subset(duplicate_sorting2, subset=c(newdate > as.Date("2020-02-10")-80))

```
```{r boxplots}

#neither work right now.

geom_boxplot(outlier.colour="black", outlier.shape=16,
             outlier.size=2, notch=FALSE)

boxplot(pm25~newdate,data=all_afterlockdown2020, main="Pollution After 2020 Lockdown",
   xlab="PM 2.5", ylab="Date")

#next: boxplot of the city means before, boxplot of the city means after.

#NEW idea: given file with id, newdate, before vs after, pollutant levels

all_beforelockdown2020$timegroup = "before_2020"
all_afterlockdown2020$timegroup = "after_2020"

head(all_afterlockdown2020)

all_2020_timegroup <- rbind(all_beforelockdown2020, all_afterlockdown2020)
write.csv(all_2020_timegroup, "/home/CAMPUS/dapa2019/R/China_air_pollution_COVID/data/all_2020_timegroup.csv")
str(all_2020_timegroup) #created timegroup as chr

boxplot(pm25~timegroup,data=all_2020_timegroup, main="PM 2.5 Before and After 2020 Lockdown",
   xlab="time groupings ranging 80 days each", ylab="PM 2.5") #works, but need to reoirent x axis

#all four timegroups: 
all_beforelockdown2019$timegroup = "before_2019"
all_afterlockdown2019$timegroup = "after_2019"
all_2019_timegroup <- rbind(all_beforelockdown2019, all_afterlockdown2019)
write.csv(all_2019_timegroup, "/home/CAMPUS/dapa2019/R/China_air_pollution_COVID/data/all_2019_timegroup.csv")
str(all_2019_timegroup)

all_four_timegroup <- rbind(all_2019_timegroup, all_2020_timegroup)
write.csv(all_four_timegroup, "/home/CAMPUS/dapa2019/R/China_air_pollution_COVID/data/all_four_timegroup.csv")
str(all_four_timegroup)

boxplot(pm25~timegroup,data=all_four_timegroup, main="PM 2.5 Before and After Lockdown in 2020 and 2019", xlab="time groupings ranging 80 days each", ylab="PM 2.5") #works, and can use this format for all pollutants, but first need to reoirent x axis. also.. why am I getting so many outliers???
#boxplot for all data, not just the means.

help(boxplot)

#boxplot for just the means #works but only for pm25 in 2020.
cities_means_pm25.csv = "/home/CAMPUS/dapa2019/R/China_air_pollution_COVID/cities_means_pm25_revised.csv"
cities_means_pm25 <- read.csv(cities_means_pm25.csv)
boxplot(pm25~before_or_after,data=cities_means_pm25, main="Pollution Means Before and After 2020 Lockdowns", xlab="city", ylab="mean pm2.5")
head(cities_means_pm25)


```
creating boxplots of means for each pollutant.
first: create one csv with mean data from all cities.

```{r}

#find the mean for each pollutant within each time frame for each city.
#created: 
#means_allcities_allpollutants_beforelockdown2019.csv 
#means_allcities_allpollutants_afterlockdown2019.csv 
#means_allcities_allpollutants_beforelockdown2020.csv 
#means_allcities_allpollutants_afterlockdown2020.csv 

description = "yibin_afterlockdown2020"

capture.output(description, file= "means_allcities_allpollutants_afterlockdown2020.csv", append = TRUE)

citymean <- mean(yibin_afterlockdown2020$pm25, trim=0, na.rm=TRUE)
pollutiontype = "pm25"
capture.output(pollutiontype, citymean, file= "means_allcities_allpollutants_afterlockdown2020.csv", append = TRUE)

citymean <- mean(yibin_afterlockdown2020$pm10, trim=0, na.rm=TRUE)
pollutiontype = "pm10"
capture.output(pollutiontype, citymean, file= "means_allcities_allpollutants_afterlockdown2020.csv", append = TRUE)

citymean <- mean(yibin_afterlockdown2020$o3, trim=0, na.rm=TRUE)
pollutiontype = "o3"
capture.output(pollutiontype, citymean, file= "means_allcities_allpollutants_afterlockdown2020.csv", append = TRUE)

citymean <- mean(yibin_afterlockdown2020$no2, trim=0, na.rm=TRUE)
pollutiontype = "no2"
capture.output(pollutiontype, citymean, file= "means_allcities_allpollutants_afterlockdown2020.csv", append = TRUE)

citymean <- mean(yibin_afterlockdown2020$so2, trim=0, na.rm=TRUE)
pollutiontype = "so2"
capture.output(pollutiontype, citymean, file= "means_allcities_allpollutants_afterlockdown2020.csv", append = TRUE)

citymean <- mean(yibin_afterlockdown2020$co, trim=0, na.rm=TRUE)
pollutiontype = "co"
capture.output(pollutiontype, citymean, file= "means_allcities_allpollutants_afterlockdown2020.csv", append = TRUE)


#edited together manually in Excel

allmeans.csv = "/home/CAMPUS/dapa2019/R/China_air_pollution_COVID/means/means_allcities_allpollutants_alltimeframes.csv"

allmeans <- read.csv(allmeans.csv)

str(allmeans)

#boxplot showing all cities, able to specify individual pollutants, using the mean of the pollutant for each city, grouped by all four time frames.

boxplot(co~timeframe,data=allmeans, main="Mean Carbon Monoxide in 30 Cities Before and After Lockdown", xlab="80 Day Time Frames", ylab="Mean CO", names=c("2019 before","2019 after","2020 before","2020 after"))
allmeans$timeframe <- factor(allmeans$timeframe , levels=c("2019_before", "2019_after", "2020_before", "2020_after"))
 
#legend("topright", legend = c("80 days before the 2019 equivalent of the date lockdowns started", "80 days after the 2019 equivalent of the date lockdowns started", "80 days before the date lockdowns started in 2020", "80 days after the date lockdowns started in 2020"))
#trouble including legend; it blocks view of graph.

#creates tables summarizing the data shown in the boxplots
summary()

```


Running t-tests

```{r regression}

#how much of the variation in each pollutant is accounted for by time frame (by year? by before/after?), by population?

#hypothesis: pollutant levels decreased significantly after lockdown in 2020, as compared with before lockdown, controlling for seasonal effects.

#to test what's going wrong, I created regression2020only.csv file.
#also created a file taht includes comparing beforevsafter in 2020 and 2020vs2019 for "after" timeframe
regression.csv = "/home/CAMPUS/dapa2019/R/China_air_pollution_COVID/means/regression.csv"
regression <- read.csv(regression.csv)

plot <- lm(pm25 ~ timeframe+population, regression) #only three time frames showingup, and the tiny values make no sense
summary(plot)
anova(plot) #why are DF = 1 for both? 

#some of the variation in the pollutants can be explained by city population size
#pollution decreases significantly during the 2020 lockdowns


# x = time, x' = population, x" = year, y = pm25
# data frame is: city, [year, before/after], population, proximity to nearest factory, each pollutant.
#doing * instead of + can show interaction.
#look at covariance, anova, assumptions


```

```{r ttest}
 
#extract mean_before, mean_after, p-value
ttest = t.test(all_beforelockdown2020$pm25, all_afterlockdown2020$pm25)
ttest$estimate
ttest$p.value

#export whole ttest
capture.output(ttest, file = "Welch_output_allcities.csv", append = TRUE)

#export just description, estimate, pvalue
estimate = ttest$estimate
pvalue = ttest$p.value
description = "all_beforelockdown2020 vs all_afterlockdown2020"
capture.output(description, estimate, pvalue, file = "output_allcities.csv", append = TRUE)

```

run BACI analysis to see how % decreased

```{r BACI}
#group into 3 city size categories --> run an ANOVA
#pollutant as a function of after - before and city size. BACI.
#aov delta citysize
#before = WINTER 
#after = SPRING


#RESTRUCTURE FILE eg. pm25_before_2020, _after_2020, ditto for 2019.
# delta = 2019(winter-spring) - 2020(winter-spring)

regression_withdelta.csv = "/home/CAMPUS/dapa2019/R/China_air_pollution_COVID/means/regression_withdelta.csv"
regression_withdelta <- read.csv(regression_withdelta.csv)

str(regression_withdelta)

pm25.aov <- aov(pm25_2020after ~ pm25_2020minus2019 + population_discrete, data=regression_withdelta) #broke population into three categories
summary(pm25.aov) #run for every pollutant
#plot(pm25_2020after ~ pm25_2020minus2019, data=regression_withdelta)
#hist(regression_withdelta$pm25_2020afterminus2020before)
#hist(regression_withdelta$pm25_2019afterminus2019before)
#hist(regression_withdelta$pm25_2020minus2019)

#the anova is ancova? population is categorical, and have about the same number of cities in each category. analysis of covariance. see if slope and p-value are significant based on *
#presentation: tell a narrative, showing results thorughout.



#alternative approach: run two regressions per pollutant, one for each yearly data set. tehn compare experimentla and control results.
#expect population to explain more of the 2020 data set.

regression2020only.csv = "/home/CAMPUS/dapa2019/R/China_air_pollution_COVID/means/regression2020only.csv"
regression2020only <- read.csv(regression2020only.csv)
str(regression_withdelta)

pm25.aov <- aov(pm25 ~ timeframe + population, data=regression2020only) #timeframe is significant
summary(pm25.aov)

#alt approach edited for population to be discrete


regression2020only.csv = "/home/CAMPUS/dapa2019/R/China_air_pollution_COVID/means/regression2020only.csv"
regression2020only <- read.csv(regression2020only.csv)
str(regression2020only)

pm25.aov <- aov(pm25 ~ timeframe + population_discrete, data=regression2020only) #timeframe is significant
summary(pm25.aov)

```

```{r}

#now trying a hierarchical multiple regression
#(pm25_2020after ~ population + pm25before + pm25_2019after, dataset)

hierarchical_reg.csv = "/home/CAMPUS/dapa2019/R/China_air_pollution_COVID/means/hierarchical_reg.csv"
hierarchical_reg <- read.csv(hierarchical_reg.csv)
str(hierarchical_reg)

var1 <- lm(formula = pm25_after2020 ~ population_30cities, data = hierarchical_reg) #plot of residuals shows this might not be a linear model
var2 <- lm(formula = pm25_after2020 ~ population_30cities + pm25_after2019, data = hierarchical_reg)
var3 <- lm(formula = pm25_after2020 ~ population_30cities + pm25_after2019 + pm25_before2020, data = hierarchical_reg)
anova(var1,var2,var3)

#reformatted
hierarchical_reg_reformatted.csv = "/home/CAMPUS/dapa2019/R/China_air_pollution_COVID/means/hierarchical_reg_reformatted.csv"
hierarchical_reg_reformatted <- read.csv(hierarchical_reg_reformatted.csv)
str(hierarchical_reg_reformatted)

var1 <- lm(formula = pm25_all2020 ~ population_discrete, data = hierarchical_reg_reformatted) #plot of residuals shows this might not be a linear model
plot(var1) #see constant leverage
var2 <- lm(formula = pm25_all2020 ~ population_discrete + pm25_all2019, data = hierarchical_reg_reformatted)
var3 <- lm(formula = pm25_all2020 ~ population_discrete + pm25_all2019 + beforevsafter, data = hierarchical_reg_reformatted)
anova(var1,var2,var3)

#revised to include industrial GRP
hierarchical_reg_grp.csv = "/home/CAMPUS/dapa2019/R/China_air_pollution_COVID/means/hierarchical_reg_discrete_withfactories.csv"
hierarchical_reg_grp <- read.csv(hierarchical_reg_grp.csv)
str(hierarchical_reg_grp)

var_initial <- lm(formula = pm25_all2020 ~ 1, data = hierarchical_reg_grp)
var1 <- lm(formula = pm25_all2020 ~ population_30cities, data = hierarchical_reg_grp) #plot of residuals shows this might not be a linear model
plot(var1) #see constant leverage
var2 <- lm(formula = pm25_all2020 ~ population_30cities + industry, data = hierarchical_reg_grp)
var3 <- lm(formula = pm25_all2020 ~ population_30cities + industry + pm25_all2019, data = hierarchical_reg_grp)
var4 <- lm(formula = pm25_all2020 ~ population_30cities + industry + pm25_all2019 + beforevsafter, data = hierarchical_reg_grp)
anova(var_initial, var1,var2,var3, var4)

summary(var4)

#changed the dependent variable to be pm25_after2020 and reformatted the excel
hierarchical_reg_grp_2.csv = "/home/CAMPUS/dapa2019/R/China_air_pollution_COVID/means/hierarchical_reg_discrete_withfactories_reformatteddependentvar.csv"
hierarchical_reg_grp_2 <- read.csv(hierarchical_reg_grp_2.csv)
str(hierarchical_reg_grp_2)

var_initial <- lm(formula = pm25_2020after ~ 1, data = hierarchical_reg_grp_2)
var1 <- lm(formula = pm25_2020after ~ population_30cities, data = hierarchical_reg_grp_2) #plot of residuals shows this might not be a linear model
var2 <- lm(formula = pm25_2020after ~ population_30cities + industry, data = hierarchical_reg_grp_2)
var3 <- lm(formula = pm25_2020after ~ population_30cities + industry + pm25_2019after, data = hierarchical_reg_grp_2)
var4 <- lm(formula = pm25_2020after ~ population_30cities + industry + pm25_2019after + pm25_2020before, data = hierarchical_reg_grp_2)
anova(var_initial, var1,var2,var3, var4)

summary(var2)

summary(lm(formula = pm25_2020after ~ population_30cities + industry + pm25_2019after + pm25_2020before, data = hierarchical_reg_grp_2))
summary(lm(formula = pm25_2020after ~ pm25_2020before, data = hierarchical_reg_grp_2))

#boxplots for 3 city sizes
#scatterplot color coded for covid

```

#delta approach results
#only reports change not decrease!
                   Df Sum Sq Mean Sq F value Pr(>F)
pm25_2020minus2019  1     66   66.17   0.242  0.627
population          1    251  251.36   0.918  0.346
Residuals          27   7390  273.70               
90 observations deleted due to missingness

#delta approach results with 3 discrete population groupings
                    Df Sum Sq Mean Sq F value Pr(>F)
pm25_2020minus2019   1    388   388.0   1.436  0.242
population_discrete  2    295   147.6   0.546  0.586
Residuals           26   7024   270.2               
90 observations deleted due to missingness


#alternative approach results
#2019only
            Df Sum Sq Mean Sq F value Pr(>F)  
timeframe    1   2900  2899.5   6.652 0.0125 *
population   1    875   875.5   2.008 0.1619  
Residuals   57  24847   435.9  

#2020only
            Df Sum Sq Mean Sq F value   Pr(>F)    
timeframe    1  13941   13941  28.597 1.64e-06 ***
population   1   1719    1719   3.527   0.0655 .  
Residuals   57  27788     488                     


#hierarchical multiple regression. 
#(degrees of freedom here are confusing)
Analysis of Variance Table 

Model 1: pm25_after2020 ~ population_30cities
Model 2: pm25_after2020 ~ population_30cities + pm25_after2019
Model 3: pm25_after2020 ~ population_30cities + pm25_after2019 + pm25_before2020
  Res.Df    RSS Df Sum of Sq       F    Pr(>F)    
1     28 7445.3                                   
2     27 2121.1  1    5324.2 88.9942 7.037e-10 ***
3     26 1555.5  1     565.6  9.4537  0.004906 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 

#reformatted. seems more effective!
Analysis of Variance Table

Model 1: pm25_all2020 ~ population_30cities
Model 2: pm25_all2020 ~ population_30cities + pm25_all2019
Model 3: pm25_all2020 ~ population_30cities + pm25_all2019 + beforevsafter
  Res.Df   RSS Df Sum of Sq       F    Pr(>F)    
1     58 41729                                   
2     57 15830  1   25899.3 132.352 2.236e-16 ***
3     56 10958  1    4871.7  24.896 6.218e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

#reformatted, and making population discrete makes little/no difference.
Analysis of Variance Table

Model 1: pm25_all2020 ~ population_discrete
Model 2: pm25_all2020 ~ population_discrete + pm25_all2019
Model 3: pm25_all2020 ~ population_discrete + pm25_all2019 + beforevsafter
  Res.Df   RSS Df Sum of Sq       F    Pr(>F)    
1     57 41131                                   
2     56 15026  1     26105 141.863 < 2.2e-16 ***
3     55 10121  1      4905  26.655 3.457e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

#CHANGE to include GRP

#including industrial gross regional product where the region is each city's province or autonomous region
Analysis of Variance Table

Model 1: pm25_all2020 ~ 1
Model 2: pm25_all2020 ~ population_discrete
Model 3: pm25_all2020 ~ population_discrete + industry
Model 4: pm25_all2020 ~ population_discrete + industry + pm25_all2019
Model 5: pm25_all2020 ~ population_discrete + industry + pm25_all2019 + 
    beforevsafter
  Res.Df   RSS Df Sum of Sq        F    Pr(>F)    
1     59 43449                                    
2     57 41131  2    2317.7   7.5306  0.001304 ** 
3     56 41065  1      66.3   0.4307  0.514426    
4     55 12698  1   28366.8 184.3378 < 2.2e-16 ***
5     54  8310  1    4388.3  28.5167   1.9e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
#summary statistics: questions:
#why are there 54 DF???
#why is medium population significant, and big nonexistent in the data?
Call:
lm(formula = pm25_all2020 ~ population_discrete + industry + 
    pm25_all2019 + beforevsafter, data = hierarchical_reg_grp)

Residuals:
    Min      1Q  Median      3Q     Max 
-20.142  -7.517  -0.605   5.147  66.137 

Coefficients:
                            Estimate Std. Error t value Pr(>|t|)    
(Intercept)               -0.1059525  9.9437266  -0.011  0.99154    
population_discretemedium  9.6812602  3.9366970   2.459  0.01716 *  
population_discretesmall   4.0572823  4.1974786   0.967  0.33805    
industry                  -0.0005519  0.0001609  -3.431  0.00116 ** 
pm25_all2019               0.8896606  0.0804611  11.057 1.73e-15 ***
beforevsafterbefore       18.1173713  3.3927008   5.340 1.90e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 12.41 on 54 degrees of freedom
Multiple R-squared:  0.8087,	Adjusted R-squared:  0.791 
F-statistic: 45.67 on 5 and 54 DF,  p-value: < 2.2e-16

#same as above with continuous not discrete population
Analysis of Variance Table

Model 1: pm25_all2020 ~ 1
Model 2: pm25_all2020 ~ population_30cities
Model 3: pm25_all2020 ~ population_30cities + industry
Model 4: pm25_all2020 ~ population_30cities + industry + pm25_all2019
Model 5: pm25_all2020 ~ population_30cities + industry + pm25_all2019 + 
    beforevsafter
  Res.Df   RSS Df Sum of Sq        F    Pr(>F)    
1     59 43449                                    
2     58 41729  1    1719.5  10.4843  0.002043 ** 
3     57 41484  1     245.1   1.4946  0.226721    
4     56 13451  1   28033.2 170.9278 < 2.2e-16 ***
5     55  9020  1    4430.7  27.0156 3.051e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
#summary statistics
Call:
lm(formula = pm25_all2020 ~ population_30cities + industry + 
    pm25_all2019 + beforevsafter, data = hierarchical_reg_grp)

Residuals:
    Min      1Q  Median      3Q     Max 
-18.091  -6.211  -1.306   5.058  70.779 

Coefficients:
                      Estimate Std. Error t value Pr(>|t|)    
(Intercept)          6.354e+00  1.065e+01   0.597  0.55320    
population_30cities -3.157e-07  2.684e-07  -1.176  0.24458    
industry            -5.250e-04  1.527e-04  -3.438  0.00113 ** 
pm25_all2019         8.833e-01  8.312e-02  10.627 6.04e-15 ***
beforevsafterbefore  1.821e+01  3.503e+00   5.198 3.05e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 12.81 on 55 degrees of freedom
Multiple R-squared:  0.7924,	Adjusted R-squared:  0.7773 
F-statistic: 52.48 on 4 and 55 DF,  p-value: < 2.2e-16

#multiple r-squared values from the summary() for each individual var#. 
#Compared r squared values to check for multicollinearity and none found.
var1 Multiple R-squared:  0.03958 #population
var2 Multiple R-squared:  0.04522 #industrial GRP
var3 Multiple R-squared:  0.6904 #expected seasonal changes
var4 Multiple R-squared:  0.7924 #lockdown



#reformatted to change the dependent variable (unsure if I should even have done this)
Analysis of Variance Table

Model 1: pm25_2020after ~ 1
Model 2: pm25_2020after ~ population_30cities
Model 3: pm25_2020after ~ population_30cities + industry
Model 4: pm25_2020after ~ population_30cities + industry + pm25_2019after
Model 5: pm25_2020after ~ population_30cities + industry + pm25_2019after + pm25_2020before
  Res.Df    RSS Df Sum of Sq        F    Pr(>F)    
1     29 7707.5                                    
2     28 7445.3  1     262.2   5.4270   0.02820 *  
3     27 7391.8  1      53.5   1.1080   0.30260    
4     26 1461.4  1    5930.4 122.7348 3.903e-11 ***
5     25 1208.0  1     253.4   5.2438   0.03074 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

#with summary(var#)
var1 Multiple R-squared:  0.03402 #population
var2 Multiple R-squared:  0.04097 #industrial GRP
var3 Multiple R-squared:  0.8104 #compared to the same months in 2019
var4 Multiple R-squared:  0.8433 #compared to before lockdown in 2020

#with summary(lm(formula = pm25_2020after ~ #one_variable#, data = hierarchical_reg_grp_2))
population_30cities Multiple R-squared:  0.03402
industry            Multiple R-squared:  0.006941
pm25_2019after      Multiple R-squared:  0.7133
pm25_2020before     Multiple R-squared:  0.5757

